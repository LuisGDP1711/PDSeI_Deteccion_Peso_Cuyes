{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuisGDP1711/PDSeI_Deteccion_Peso_Cuyes/blob/main/PROYECTO/Colab_NoteBooks/PyTorch_Estimacion_cuyes_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PDSI - Redes Neuronales convolucionales\n",
        "Utilizando PyTorch y la arquitectura ResNet"
      ],
      "metadata": {
        "id": "gOloQjwmhwdg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalaciones previas"
      ],
      "metadata": {
        "id": "bD8p9HLEh-hA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Montar Google Drive"
      ],
      "metadata": {
        "id": "VrLAGqfaYU1W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZu7p0tlg60y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a10edaf-61eb-4eb1-bfeb-b6f1bd8c87df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cargar e inspeccionar los datos"
      ],
      "metadata": {
        "id": "X7GiRGOOJ_Gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "weights_path = '/content/drive/MyDrive/cuyes/weights_train.txt'\n",
        "weights_df = pd.read_csv(weights_path, header=None, names=['filename', 'weight'])\n",
        "weights_df['weight'] = weights_df['weight'].astype(float)"
      ],
      "metadata": {
        "id": "nhVGIVLbJ-jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(weights_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxP5wee7KZ-X",
        "outputId": "75aded9b-ece9-4a09-989a-cf6e45b42b39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              filename     weight\n",
            "0  B_CUY_01_001_01.jpg  308.44256\n",
            "1  B_CUY_01_001_02.jpg  308.44256\n",
            "2  B_CUY_01_001_03.jpg  308.44256\n",
            "3  B_CUY_01_001_04.jpg  308.44256\n",
            "4  B_CUY_01_001_05.jpg  308.44256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configurar el dataset para la tarea de regresión"
      ],
      "metadata": {
        "id": "3DBzrvLhYYaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models"
      ],
      "metadata": {
        "id": "YgSpy5QkiBhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GuineaPigDataset(Dataset):\n",
        "    def __init__(self, images_folder, weights_df, transform=None):\n",
        "        self.images_folder = images_folder\n",
        "        self.weights_df = weights_df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.weights_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.images_folder, self.weights_df.iloc[idx, 0])\n",
        "\n",
        "        # Verifica si el archivo existe\n",
        "        if not os.path.exists(img_name):\n",
        "            print(f\"Archivo no encontrado: {img_name}\")\n",
        "\n",
        "        image = Image.open(img_name).convert(\"RGB\")\n",
        "        weight = self.weights_df.iloc[idx, 1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(weight, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "ZPZPKyU_Ib8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformación y carga de datos\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),  # ResNet espera imágenes de 256x256\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),  # Normalización para ResNet (Saber por qué)\n",
        "])\n",
        "\n",
        "\n",
        "train_data = GuineaPigDataset('/content/drive/MyDrive/cuyes/train', weights_df, transform=transform)\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "GqyKbKECO9ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostrar los datos"
      ],
      "metadata": {
        "id": "s5NwAnZuvR7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "U3Ikfa_yvYWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener un lote de datos\n",
        "#data_loader = DataLoader(train_data, batch_size=4, shuffle=True)\n",
        "\n",
        "# Tomar un lote de datos\n",
        "images, weights = next(iter(train_loader))\n",
        "\n",
        "# Convertir las imágenes de tensor a PIL para visualizarlas\n",
        "def imshow(tensor_image):\n",
        "    image = tensor_image.permute(1, 2, 0)  # Cambiar la dimensión para Matplotlib\n",
        "    image = image.numpy()  # Convertir a numpy array\n",
        "    # Deshacer la normalización\n",
        "    image = image * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]\n",
        "    image = np.clip(image, 0, 1)  # Asegurarse de que los valores estén entre 0 y 1\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')  # Ocultar los ejes\n",
        "    plt.show()\n",
        "\n",
        "# Mostrar imágenes originales y transformadas\n",
        "for i in range(images.size(0)):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Mostrar la imagen original (cargarla de nuevo)\n",
        "    original_image_path = os.path.join('/content/drive/MyDrive/cuyes/train', weights_df.iloc[i, 0])\n",
        "    original_image = Image.open(original_image_path)\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title('Imagen Original')\n",
        "    plt.imshow(original_image)\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Mostrar la imagen transformada\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title('Imagen Transformada')\n",
        "    imshow(images[i])\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "FgZG637xvcck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modificar ResNet para regresión"
      ],
      "metadata": {
        "id": "LOt9zZTphmeQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usaremos ResNet-50 y reemplazaremos la última capa para que tenga una salida única"
      ],
      "metadata": {
        "id": "1ZRhbgVExU_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "# Cargar el modelo preentrenado ResNet-50\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Modificar la última capa para regresión\n",
        "model.fc = nn.Linear(model.fc.in_features, 1)  # 1 salida para el peso"
      ],
      "metadata": {
        "id": "dMPOwgUgibLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed24435a-b888-46b0-f2a1-7145dedf6a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 100MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configurar el entrenamiento\n",
        "\n",
        "Definiremos el optimizador, la función de pérdida y el ciclo de entrenamiento. Para regresión, usamos el error cuadrático medio (MSE) como función de pérdida."
      ],
      "metadata": {
        "id": "vMWSqp2sxW2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Configurar el dispositivo\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Definir la función de pérdida y el optimizador\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "NtBHnUPNxZx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenar el modelo\n",
        "\n"
      ],
      "metadata": {
        "id": "-OtmpedQ3S2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5  # Ajusta según el rendimiento y los recursos disponibles\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, weights in train_loader:\n",
        "        images, weights = images.to(device), weights.to(device).unsqueeze(1)  # Esto convierte weights de [batch] a [batch, 1]\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, weights)\n",
        "\n",
        "        # Backward y optimización\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
        "\n",
        "    # Guardar el modelo en cada época (opcional)\n",
        "    torch.save(model.state_dict(), f'/content/drive/MyDrive/weights_epoch_{epoch+1}.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dt6m2bw03TrT",
        "outputId": "e8fea61c-2429-43a5-c466-0435cc2791c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 194131.2556\n",
            "Epoch [2/5], Loss: 185093.3698\n",
            "Epoch [3/5], Loss: 177401.5191\n",
            "Epoch [4/5], Loss: 168929.8635\n",
            "Epoch [5/5], Loss: 159615.8142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluar el modelo"
      ],
      "metadata": {
        "id": "KN4wM4Lb5lsY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar el modelo"
      ],
      "metadata": {
        "id": "VolwpJ6lUnor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Suponiendo que tu modelo se guarda como 'model.pth'\n",
        "model = models.resnet50(pretrained=False)  # Ajusta esto si usaste una arquitectura diferente\n",
        "num_classes = 1  # Cambia esto según el número de clases (en tu caso, pesos)\n",
        "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "# Carga los pesos del modelo\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/EPOCHS/01/weights_epoch_5.pth'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrGi05wkUuCk",
        "outputId": "6cbbaa64-f7a3-49ee-f56c-34157ab68c3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-01fdfaafb581>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('/content/drive/MyDrive/EPOCHS/01/weights_epoch_5.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparar las transformaciones de la imagen"
      ],
      "metadata": {
        "id": "1Y6yJ_rdUsxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),  # Ajusta el tamaño según el modelo\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Valores típicos para modelos preentrenados\n",
        "])"
      ],
      "metadata": {
        "id": "a-9ohxsoVGRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Función para evaluar y predecir"
      ],
      "metadata": {
        "id": "rP1RfcZhVSP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, image_folder):\n",
        "    predictions = []\n",
        "\n",
        "    for img_name in os.listdir(image_folder):\n",
        "        img_path = os.path.join(image_folder, img_name)\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img = transform(img)\n",
        "        img = img.unsqueeze(0)  # Añadir dimensión de batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(img)\n",
        "            prediction = output.item()  # Obtener el valor escalar\n",
        "            predictions.append((img_name, prediction))\n",
        "\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "u4hqXOrNVTk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejecutar la evaluación**\n",
        "\n",
        "Llama a la función y pasa la carpeta de imágenes de prueba."
      ],
      "metadata": {
        "id": "W8cdimQfVY3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = '/content/drive/MyDrive/cuyes/test'\n",
        "predictions = evaluate_model(model, image_folder)\n",
        "\n",
        "# Convertir a un DataFrame para facilitar la visualización\n",
        "predictions_df = pd.DataFrame(predictions, columns=['Imagen', 'Predicción (gramos)'])\n",
        "print(predictions_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7opFQLRVuBf",
        "outputId": "e17543e9-1310-4439-a5c2-25071286611c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Imagen  Predicción (gramos)\n",
            "0   B_CUY_01_014_01.jpg            86.009407\n",
            "1   B_CUY_01_014_02.jpg            85.982292\n",
            "2   B_CUY_01_014_03.jpg            92.787910\n",
            "3   B_CUY_01_014_04.jpg            95.265587\n",
            "4   B_CUY_01_014_05.jpg            69.545288\n",
            "..                  ...                  ...\n",
            "74  B_CUY_01_045_09.jpg            91.140076\n",
            "75  B_CUY_01_045_10.jpg            93.178047\n",
            "76  B_CUY_01_045_11.jpg            86.583542\n",
            "77  B_CUY_01_045_12.jpg            90.328331\n",
            "78  B_CUY_01_045_13.jpg           104.312302\n",
            "\n",
            "[79 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluar la precisión**\n",
        "\n",
        "Comparar las predicciones con los pesos reales para evaluar el rendimiento del modelo."
      ],
      "metadata": {
        "id": "Uy3XIEWhV0Gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar los pesos reales\n",
        "weights_df = pd.read_csv('/content/drive/MyDrive/cuyes/weights_test.txt', sep=',', header=None, names=['Imagen', 'Peso'])\n",
        "merged_df = pd.merge(predictions_df, weights_df, on='Imagen', how='inner')\n",
        "merged_df['Error'] = merged_df['Predicción (gramos)'] - merged_df['Peso']\n",
        "\n",
        "print(merged_df.head())  # Muestra las primeras filas del DataFrame\n",
        "#print(merged_df.info())  # Información sobre el DataFrame (incluyendo conteo de nulos)"
      ],
      "metadata": {
        "id": "4s4xUpuP6w0I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a7417a2-8fa6-46cb-9f84-513f77260db2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Imagen  Predicción (gramos)       Peso       Error\n",
            "0  B_CUY_01_014_01.jpg            86.009407  648.63656 -562.627153\n",
            "1  B_CUY_01_014_02.jpg            85.982292  648.63656 -562.654268\n",
            "2  B_CUY_01_014_03.jpg            92.787910  648.63656 -555.848650\n",
            "3  B_CUY_01_014_04.jpg            95.265587  648.63656 -553.370973\n",
            "4  B_CUY_01_014_05.jpg            69.545288  648.63656 -579.091272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardar los resultados de la prueba"
      ],
      "metadata": {
        "id": "RslFz3EaaFgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el DataFrame en un archivo .txt\n",
        "ruta = '/content/drive/MyDrive/RESULTADOS/01/resultados_errores.txt'\n",
        "merged_df.to_csv(ruta, sep='\\t', index=False)\n",
        "\n",
        "print(\"Archivo 'resultados_errores.txt' generado exitosamente.\")"
      ],
      "metadata": {
        "id": "C63kmNexaG28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metricas"
      ],
      "metadata": {
        "id": "AdrTvKu6aLUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular métricas como el error cuadrático medio (RMSE)\n",
        "rmse = (merged_df['Error']**2).mean()**0.5\n",
        "print(f'RMSE: {rmse:.4f}')\n",
        "\n",
        "# Calculamos el MAE (Mean Absolute Error)\n",
        "mae = (merged_df['Predicción (gramos)'] - merged_df['Peso']).abs().mean()\n",
        "print(f'MAE: {mae:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IM97GP4W813",
        "outputId": "8abf12e4-8cbb-440b-9459-949fcf709a46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 728.3760475980049\n"
          ]
        }
      ]
    }
  ]
}